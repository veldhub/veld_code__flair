{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a6bddb-724e-47c4-9969-5eaed5a388e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 12:41:56,814 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "2025-01-28 12:41:59,538 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "2025-01-28 12:42:28,677 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "2025-01-28 12:42:39,743 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "2025-01-28 12:42:42,076 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n",
      "2025-01-28 12:42:43,958 SequenceTagger predicts: Dictionary with 4852 tags: <unk>, be.01, be.03, have.01, say.01, do.01, have.03, do.02, be.02, know.01, think.01, come.01, see.01, want.01, go.02, tell.01, give.01, use.01, make.02, take.01, talk.01, get.01, go.04, live.01, need.01, believe.01, work.01, mean.01, have.02, look.01, become.01, die.01, help.01, find.01, try.01, hear.01, know.06, show.01, happen.01, let.01, sell.01, bring.01, make.01, invest.01, begin.01, make.LV, continue.01, kill.01, speak.01, start.01\n",
      "2025-01-28 12:42:45,748 SequenceTagger predicts: Dictionary with 47 tags: O, S-NP, B-NP, E-NP, I-NP, S-VP, B-VP, E-VP, I-VP, S-PP, B-PP, E-PP, I-PP, S-ADVP, B-ADVP, E-ADVP, I-ADVP, S-SBAR, B-SBAR, E-SBAR, I-SBAR, S-ADJP, B-ADJP, E-ADJP, I-ADJP, S-PRT, B-PRT, E-PRT, I-PRT, S-CONJP, B-CONJP, E-CONJP, I-CONJP, S-INTJ, B-INTJ, E-INTJ, I-INTJ, S-LST, B-LST, E-LST, I-LST, S-UCP, B-UCP, E-UCP, I-UCP, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "from flair.splitter import SegtokSentenceSplitter\n",
    "splitter = SegtokSentenceSplitter()\n",
    "tagger_ner = Classifier.load('ner')\n",
    "tagger_ner_english_fast = Classifier.load('flair/ner-english-fast')\n",
    "tagger_sent = Classifier.load('sentiment')\n",
    "tagger_ner_english_large = Classifier.load('flair/ner-english-large')\n",
    "tagger_linker = Classifier.load('linker')\n",
    "tagger_pos = Classifier.load('flair/pos-english')\n",
    "tagger_frame = Classifier.load('frame')\n",
    "tagger_chunk = Classifier.load('chunk')\n",
    "extractor_relations = Classifier.load('relations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd52cda-ca53-424a-b1d8-8e49da8d0d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[4]: \"I love Berlin .\"\n",
      "Sentence[4]: \"I love Berlin .\" → [\"Berlin\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('I love Berlin .')\n",
    "print(sentence)\n",
    "tagger_ner.predict(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ef1d92-276b-4a71-8507-fb4b7e4c43ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[4]: \"I love Berlin .\"\n",
      "Sentence[4]: \"I love Berlin .\" → POSITIVE (0.9983)\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('I love Berlin .')\n",
    "print(sentence)\n",
    "tagger_sent.predict(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de5b5e6-44d0-4c49-acb4-3ea4f42e0555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[0]: \"The\"\n",
      "Token[1]: \"grass\"\n",
      "Token[2]: \"is\"\n",
      "Token[3]: \"green\"\n",
      "Token[4]: \".\"\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('The grass is green.')\n",
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eab660f-af07-4d43-b37f-65b3b90a7229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[3]: \"green\"\n",
      "Token[3]: \"green\"\n"
     ]
    }
   ],
   "source": [
    "print(sentence.get_token(4))\n",
    "print(sentence[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee3e718-8766-48da-af2d-c330cc26d23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[5]: \"The grass is green.\" → [\"green\"/color]\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('The grass is green.')\n",
    "sentence[3].add_label('ner', 'color')\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e24bae-3a7c-4469-8cc4-937cfc60294e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[5]: \"The grass is green.\" → POSITIVE (1.0000)\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('The grass is green.')\n",
    "sentence.add_label('sentiment', 'POSITIVE')\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ebd3bf3-c70f-4893-85fc-b0b9f86dedb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[5]: \"The grass is green.\" → POSITIVE (1.0)\n"
     ]
    }
   ],
   "source": [
    "for label in sentence.get_labels():\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22dca967-e617-493e-8a77-80ca7694eaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[6]: \"George Washington went to Washington.\" → [\"George Washington\"/PER, \"Washington\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('George Washington went to Washington.')\n",
    "tagger_ner.predict(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f13a6451-5a40-4f91-8f87-788ca082c59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label.value is: \"PER\"\n",
      "label.score is: \"0.998886227607727\"\n",
      "the text of label.data_point is: \"George Washington\"\n",
      "\n",
      "label.value is: \"LOC\"\n",
      "label.score is: \"0.9942097663879395\"\n",
      "the text of label.data_point is: \"Washington\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in sentence.get_labels():\n",
    "    print(f'label.value is: \"{label.value}\"')\n",
    "    print(f'label.score is: \"{label.score}\"')\n",
    "    print(f'the text of label.data_point is: \"{label.data_point.text}\"\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9edbee62-5084-458e-968c-d66b6f7dd6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[6]: \"George Washington went to Washington.\" → [\"George Washington\"/PER, \"Washington\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('George Washington went to Washington.')\n",
    "tagger_ner_english_large.predict(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "445e5b37-b038-45b3-90a6-1a518179632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span[0:1]: \"Kirk\" → James_T._Kirk (0.9969)\n",
      "Span[2:3]: \"Spock\" → Spock (0.9971)\n",
      "Span[6:7]: \"Enterprise\" → USS_Enterprise_(NCC-1701-D) (0.975)\n"
     ]
    }
   ],
   "source": [
    "#from flair.nn import Classifier\n",
    "#from flair.data import Sentence\n",
    "#tagger = Classifier.load('linker')\n",
    "\n",
    "sentence = Sentence('Kirk and Spock met on the Enterprise.')\n",
    "tagger_linker.predict(sentence)\n",
    "for label in sentence.get_labels():\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a387c3e-950a-4f29-a8de-a24d4704e9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[5]: \"Bayern played against Barcelona.\" → [\"Bayern\"/FC_Bayern_Munich, \"Barcelona\"/FC_Barcelona]\n",
      "Sentence[7]: \"The match took place in Barcelona.\" → [\"Barcelona\"/Barcelona]\n"
     ]
    }
   ],
   "source": [
    "#from flair.nn import Classifier\n",
    "#from flair.splitter import SegtokSentenceSplitter\n",
    "#splitter = SegtokSentenceSplitter()\n",
    "#tagger = Classifier.load('linker')\n",
    "\n",
    "text = \"Bayern played against Barcelona. The match took place in Barcelona.\"\n",
    "sentences = splitter.split(text)\n",
    "tagger_linker.predict(sentences)\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3143aab-4bb0-449c-8caa-53f27f29b9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[6]: \"Dirk went to the store.\" → [\"Dirk\"/NNP, \"went\"/VBD, \"to\"/IN, \"the\"/DT, \"store\"/NN, \".\"/.]\n"
     ]
    }
   ],
   "source": [
    "#from flair.nn import Classifier\n",
    "#from flair.data import Sentence\n",
    "#tagger = Classifier.load('flair/pos-english')\n",
    "\n",
    "sentence = Sentence('Dirk went to the store.')\n",
    "tagger_pos.predict(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bcc1525-ab20-4784-94e0-ec43f3861f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[0]: \"George\"\n",
      "Token[1]: \"returned\" → return.01 (1.0000)\n",
      "Token[2]: \"to\"\n",
      "Token[3]: \"Berlin\"\n",
      "Token[4]: \"to\"\n",
      "Token[5]: \"return\" → return.02 (0.9759)\n",
      "Token[6]: \"his\"\n",
      "Token[7]: \"hat\"\n",
      "Token[8]: \".\"\n"
     ]
    }
   ],
   "source": [
    "#from flair.nn import Classifier\n",
    "#from flair.data import Sentence\n",
    "#tagger = Classifier.load('frame')\n",
    "\n",
    "sentence = Sentence('George returned to Berlin to return his hat.')\n",
    "tagger_frame.predict(sentence)\n",
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1a4c872-9014-4d60-bed9-82e875240c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span[0:4]: \"The quick brown fox\" → NP (0.9978)\n",
      "Span[4:5]: \"jumps\" → VP (1.0)\n",
      "Span[5:6]: \"over\" → PP (0.9999)\n",
      "Span[6:9]: \"the lazy dog\" → NP (0.9986)\n"
     ]
    }
   ],
   "source": [
    "#from flair.nn import Classifier\n",
    "#from flair.data import Sentence\n",
    "#tagger = Classifier.load('chunk')\n",
    "\n",
    "sentence = Sentence('The quick brown fox jumps over the lazy dog.')\n",
    "tagger_chunk.predict(sentence)\n",
    "for chunk in sentence.get_labels():\n",
    "  print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a3d16c7-0bb8-4de4-acef-537f80c42f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span[0:1]: \"George\" → PER (0.9971)\n",
      "Span[4:5]: \"Washington\" → LOC (0.9847)\n",
      "Relation[0:1][4:5]: \"George -> Washington\" → born_in (1.0)\n",
      "Relation[0:1][4:5]: \"George -> Washington\" → born_in (1.0)\n"
     ]
    }
   ],
   "source": [
    "#from flair.data import Sentence\n",
    "#from flair.nn import Classifier\n",
    "#tagger = Classifier.load('ner-fast')\n",
    "#extractor = Classifier.load('relations')\n",
    "\n",
    "sentence = Sentence(\"George was born in Washington\")\n",
    "tagger_ner_english_fast.predict(sentence)\n",
    "entities = sentence.get_labels('ner')\n",
    "for entity in entities:\n",
    "    print(entity)\n",
    "extractor_relations.predict(sentence)\n",
    "relations = sentence.get_labels('relation')\n",
    "for relation in relations:\n",
    "    print(relation)\n",
    "for label in sentence.get_labels('relation'):\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c8f6d28-9aa2-473a-ad69-3a3730ad3408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[5]: \"This is a sentence.\"\n",
      "Sentence[5]: \"This is another sentence.\"\n",
      "Sentence[4]: \"I love Berlin.\" → [\"Berlin\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "#from flair.nn import Classifier\n",
    "#from flair.splitter import SegtokSentenceSplitter\n",
    "#splitter = SegtokSentenceSplitter()\n",
    "#tagger = Classifier.load('ner')\n",
    "\n",
    "text = \"This is a sentence. This is another sentence. I love Berlin.\"\n",
    "sentences = splitter.split(text)\n",
    "tagger_ner.predict(sentences)\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
