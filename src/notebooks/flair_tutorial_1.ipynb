{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd52cda-ca53-424a-b1d8-8e49da8d0d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 09:59:30,250 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Sentence[4]: \"I love Berlin .\" → [\"Berlin\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "\n",
    "# make a sentence\n",
    "sentence = Sentence('I love Berlin .')\n",
    "\n",
    "# load the NER tagger\n",
    "tagger = Classifier.load('ner')\n",
    "\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print the sentence with all annotations\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77ef1d92-276b-4a71-8507-fb4b7e4c43ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[4]: \"I love Berlin .\" → POSITIVE (0.9983)\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "\n",
    "# make a sentence\n",
    "sentence = Sentence('I love Berlin .')\n",
    "\n",
    "# load the NER tagger\n",
    "tagger = Classifier.load('sentiment')\n",
    "\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print the sentence with all annotations\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5de5b5e6-44d0-4c49-acb4-3ea4f42e0555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[0]: \"The\"\n",
      "Token[1]: \"grass\"\n",
      "Token[2]: \"is\"\n",
      "Token[3]: \"green\"\n",
      "Token[4]: \".\"\n"
     ]
    }
   ],
   "source": [
    "# The sentence objects holds a sentence that we may want to embed or tag\n",
    "from flair.data import Sentence\n",
    "\n",
    "# Make a sentence object by passing a string\n",
    "sentence = Sentence('The grass is green.')\n",
    "\n",
    "# Print the object to see what's in there\n",
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eab660f-af07-4d43-b37f-65b3b90a7229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[3]: \"green\"\n",
      "Token[3]: \"green\"\n"
     ]
    }
   ],
   "source": [
    "# using the token id\n",
    "print(sentence.get_token(4))\n",
    "# using the index itself\n",
    "print(sentence[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee3e718-8766-48da-af2d-c330cc26d23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[5]: \"The grass is green.\" → [\"green\"/color]\n"
     ]
    }
   ],
   "source": [
    "# Make a sentence object by passing a string\n",
    "sentence = Sentence('The grass is green.')\n",
    "\n",
    "# add an NER tag to token 3 in the sentence\n",
    "sentence[3].add_label('ner', 'color')\n",
    "\n",
    "# print the sentence (now with this annotation)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e24bae-3a7c-4469-8cc4-937cfc60294e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[5]: \"The grass is green.\" → POSITIVE (1.0000)\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('The grass is green.')\n",
    "\n",
    "# add a label to a sentence\n",
    "sentence.add_label('sentiment', 'POSITIVE')\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ebd3bf3-c70f-4893-85fc-b0b9f86dedb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[5]: \"The grass is green.\" → POSITIVE (1.0)\n"
     ]
    }
   ],
   "source": [
    "# iterate over all labels and print\n",
    "for label in sentence.get_labels():\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d4d970d-7612-44b6-b853-39346ddf372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:02:22,625 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Sentence[6]: \"George Washington went to Washington.\" → [\"George Washington\"/PER, \"Washington\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "from flair.nn import Classifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "# load the model\n",
    "tagger = Classifier.load('ner')\n",
    "\n",
    "# make a sentence\n",
    "sentence = Sentence('George Washington went to Washington.')\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print the sentence with the tags\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f13a6451-5a40-4f91-8f87-788ca082c59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label.value is: \"PER\"\n",
      "label.score is: \"0.998886227607727\"\n",
      "the text of label.data_point is: \"George Washington\"\n",
      "\n",
      "label.value is: \"LOC\"\n",
      "label.score is: \"0.9942097663879395\"\n",
      "the text of label.data_point is: \"Washington\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate over all labels in the sentence\n",
    "for label in sentence.get_labels():\n",
    "    # print label value and score\n",
    "    print(f'label.value is: \"{label.value}\"')\n",
    "    print(f'label.score is: \"{label.score}\"')\n",
    "    # access the data point to which label attaches and print its text\n",
    "    print(f'the text of label.data_point is: \"{label.data_point.text}\"\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9edbee62-5084-458e-968c-d66b6f7dd6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:08:03,405 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Sentence[6]: \"George Washington went to Washington.\" → [\"George Washington\"/PER, \"Washington\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "\n",
    "# make a sentence\n",
    "sentence = Sentence('George Washington went to Washington.')\n",
    "\n",
    "# load the NER tagger\n",
    "tagger = Classifier.load('flair/ner-english-large')\n",
    "\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print the sentence with all annotations\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "445e5b37-b038-45b3-90a6-1a518179632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:10:33,346 https://nlp.informatik.hu-berlin.de/resources/models/zelda/v2/zelda-v2.pt not found in cache, downloading to /tmp/tmpkm3bw_5w\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.76G/1.76G [03:09<00:00, 9.97MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:13:43,357 copying /tmp/tmpkm3bw_5w to cache at /root/.flair/models/zelda-v2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:13:49,120 removing temp file /tmp/tmpkm3bw_5w\n",
      "2025-01-28 10:14:00,312 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Span[0:1]: \"Kirk\" → James_T._Kirk (0.9969)\n",
      "Span[2:3]: \"Spock\" → Spock (0.9971)\n",
      "Span[6:7]: \"Enterprise\" → USS_Enterprise_(NCC-1701-D) (0.975)\n"
     ]
    }
   ],
   "source": [
    "from flair.nn import Classifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "# load the model\n",
    "tagger = Classifier.load('linker')\n",
    "\n",
    "# make a sentence\n",
    "sentence = Sentence('Kirk and Spock met on the Enterprise.')\n",
    "\n",
    "# predict entity links\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# iterate over predicted entities and print\n",
    "for label in sentence.get_labels():\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a387c3e-950a-4f29-a8de-a24d4704e9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:14:12,454 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Sentence[5]: \"Bayern played against Barcelona.\" → [\"Bayern\"/FC_Bayern_Munich, \"Barcelona\"/FC_Barcelona]\n",
      "Sentence[7]: \"The match took place in Barcelona.\" → [\"Barcelona\"/Barcelona]\n"
     ]
    }
   ],
   "source": [
    "from flair.nn import Classifier\n",
    "from flair.splitter import SegtokSentenceSplitter\n",
    "\n",
    "# example text with many sentences\n",
    "text = \"Bayern played against Barcelona. The match took place in Barcelona.\"\n",
    "\n",
    "# initialize sentence splitter\n",
    "splitter = SegtokSentenceSplitter()\n",
    "\n",
    "# use splitter to split text into list of sentences\n",
    "sentences = splitter.split(text)\n",
    "\n",
    "# predict tags for sentences\n",
    "tagger = Classifier.load('linker')\n",
    "tagger.predict(sentences)\n",
    "\n",
    "# iterate through sentences and print predicted labels\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3143aab-4bb0-449c-8caa-53f27f29b9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:16:52,319 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n",
      "Sentence[6]: \"Dirk went to the store.\" → [\"Dirk\"/NNP, \"went\"/VBD, \"to\"/IN, \"the\"/DT, \"store\"/NN, \".\"/.]\n"
     ]
    }
   ],
   "source": [
    "from flair.nn import Classifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "# load the model\n",
    "tagger = Classifier.load('flair/pos-english')\n",
    "\n",
    "# make a sentence\n",
    "sentence = Sentence('Dirk went to the store.')\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e6633ee-d956-4757-8e5b-2d75871e605b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:17:19,203 https://nlp.informatik.hu-berlin.de/resources/models/de-pos/de-pos-ud-hdt-v0.5.pt not found in cache, downloading to /tmp/tmpbhsu9y2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237M/237M [00:19<00:00, 12.9MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:17:38,675 copying /tmp/tmpbhsu9y2s to cache at /root/.flair/models/de-pos-ud-hdt-v0.5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:17:39,720 removing temp file /tmp/tmpbhsu9y2s\n",
      "2025-01-28 10:17:39,886 SequenceTagger predicts: Dictionary with 58 tags: <unk>, O, APPR, ART, ADJA, NN, VVFIN, PIS, NE, FM, $,, KON, $., CARD, APPRART, $(, PROAV, KOUS, PPER, ADV, VVINF, VAFIN, VMFIN, ADJD, PTKVZ, PTKNEG, KOKOM, PIDAT, PIAT, VVPP, PRF, PTKA, TRUNC, PPOSAT, VVIZU, PTKZU, VAINF, VMINF, PWAV, PDAT, PRELS, KOUI, APPO, VAPP, PWAT, PWS, VVIMP, APZR, PDS, PRELAT\n",
      "Sentence[7]: \"Dort hatte er einen Hut gekauft.\" → [\"Dort\"/ADV, \"hatte\"/VAFIN, \"er\"/PPER, \"einen\"/ART, \"Hut\"/NN, \"gekauft\"/VVPP, \".\"/$.]\n"
     ]
    }
   ],
   "source": [
    "from flair.nn import Classifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "# load the model\n",
    "tagger = Classifier.load('de-pos')\n",
    "\n",
    "# make a sentence\n",
    "sentence = Sentence('Dort hatte er einen Hut gekauft.')\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bcc1525-ab20-4784-94e0-ec43f3861f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:18:36,169 SequenceTagger predicts: Dictionary with 4852 tags: <unk>, be.01, be.03, have.01, say.01, do.01, have.03, do.02, be.02, know.01, think.01, come.01, see.01, want.01, go.02, tell.01, give.01, use.01, make.02, take.01, talk.01, get.01, go.04, live.01, need.01, believe.01, work.01, mean.01, have.02, look.01, become.01, die.01, help.01, find.01, try.01, hear.01, know.06, show.01, happen.01, let.01, sell.01, bring.01, make.01, invest.01, begin.01, make.LV, continue.01, kill.01, speak.01, start.01\n",
      "Token[0]: \"George\"\n",
      "Token[1]: \"returned\" → return.01 (1.0000)\n",
      "Token[2]: \"to\"\n",
      "Token[3]: \"Berlin\"\n",
      "Token[4]: \"to\"\n",
      "Token[5]: \"return\" → return.02 (0.9759)\n",
      "Token[6]: \"his\"\n",
      "Token[7]: \"hat\"\n",
      "Token[8]: \".\"\n"
     ]
    }
   ],
   "source": [
    "from flair.nn import Classifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "# load model\n",
    "tagger = Classifier.load('frame')\n",
    "\n",
    "# make English sentence\n",
    "sentence = Sentence('George returned to Berlin to return his hat.')\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# go through tokens and print predicted frame (if one is predicted)\n",
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1a4c872-9014-4d60-bed9-82e875240c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:19:14,056 SequenceTagger predicts: Dictionary with 47 tags: O, S-NP, B-NP, E-NP, I-NP, S-VP, B-VP, E-VP, I-VP, S-PP, B-PP, E-PP, I-PP, S-ADVP, B-ADVP, E-ADVP, I-ADVP, S-SBAR, B-SBAR, E-SBAR, I-SBAR, S-ADJP, B-ADJP, E-ADJP, I-ADJP, S-PRT, B-PRT, E-PRT, I-PRT, S-CONJP, B-CONJP, E-CONJP, I-CONJP, S-INTJ, B-INTJ, E-INTJ, I-INTJ, S-LST, B-LST, E-LST, I-LST, S-UCP, B-UCP, E-UCP, I-UCP, <START>, <STOP>\n",
      "Span[0:4]: \"The quick brown fox\" → NP (0.9978)\n",
      "Span[4:5]: \"jumps\" → VP (1.0)\n",
      "Span[5:6]: \"over\" → PP (0.9999)\n",
      "Span[6:9]: \"the lazy dog\" → NP (0.9986)\n"
     ]
    }
   ],
   "source": [
    "from flair.nn import Classifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "# load model\n",
    "tagger = Classifier.load('chunk')\n",
    "\n",
    "# make English sentence\n",
    "sentence = Sentence('The quick brown fox jumps over the lazy dog.')\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print the chunks\n",
    "for chunk in sentence.get_labels():\n",
    "  print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a3d16c7-0bb8-4de4-acef-537f80c42f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:19:47,451 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Span[0:1]: \"George\" → PER (0.9971)\n",
      "Span[4:5]: \"Washington\" → LOC (0.9847)\n",
      "2025-01-28 10:19:47,738 https://nlp.informatik.hu-berlin.de/resources/models/relations/relations-v11.pt not found in cache, downloading to /tmp/tmpzlyr8kz9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254M/254M [00:22<00:00, 11.6MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:20:10,873 copying /tmp/tmpzlyr8kz9 to cache at /root/.flair/models/relations-v11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:20:11,743 removing temp file /tmp/tmpzlyr8kz9\n",
      "Relation[0:1][4:5]: \"George -> Washington\" → born_in (1.0)\n",
      "Relation[0:1][4:5]: \"George -> Washington\" → born_in (1.0)\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "\n",
    "# 1. make example sentence\n",
    "sentence = Sentence(\"George was born in Washington\")\n",
    "\n",
    "# 2. load entity tagger and predict entities\n",
    "tagger = Classifier.load('ner-fast')\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# check which named entities have been found in the sentence\n",
    "entities = sentence.get_labels('ner')\n",
    "for entity in entities:\n",
    "    print(entity)\n",
    "\n",
    "# 3. load relation extractor\n",
    "extractor = Classifier.load('relations')\n",
    "\n",
    "# predict relations\n",
    "extractor.predict(sentence)\n",
    "\n",
    "# check which relations have been found\n",
    "relations = sentence.get_labels('relation')\n",
    "for relation in relations:\n",
    "    print(relation)\n",
    "\n",
    "# Use the `get_labels()` method with parameter 'relation' to iterate over all relation predictions. \n",
    "for label in sentence.get_labels('relation'):\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c8f6d28-9aa2-473a-ad69-3a3730ad3408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 10:22:40,657 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Sentence[5]: \"This is a sentence.\"\n",
      "Sentence[5]: \"This is another sentence.\"\n",
      "Sentence[4]: \"I love Berlin.\" → [\"Berlin\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "from flair.nn import Classifier\n",
    "from flair.splitter import SegtokSentenceSplitter\n",
    "\n",
    "# example text with many sentences\n",
    "text = \"This is a sentence. This is another sentence. I love Berlin.\"\n",
    "\n",
    "# initialize sentence splitter\n",
    "splitter = SegtokSentenceSplitter()\n",
    "\n",
    "# use splitter to split text into list of sentences\n",
    "sentences = splitter.split(text)\n",
    "\n",
    "# predict tags for sentences\n",
    "tagger = Classifier.load('ner')\n",
    "tagger.predict(sentences)\n",
    "\n",
    "# iterate through sentences and print predicted labels\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
